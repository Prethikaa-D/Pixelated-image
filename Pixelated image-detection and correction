!pip install opendatasets
pip install pandas
import opendatasets as od
import pandas
od.download("https://www.kaggle.com/datasets/arnaud58/flickrfaceshq-dataset-ffhq")
import cv2
import numpy as np
import os

def create_pixelated_images(input_dir, output_dir, scale_factor=8):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for filename in os.listdir(input_dir):
        img_path = os.path.join(input_dir, filename)
        img = cv2.imread(img_path)

        # Downscale image
        small_img = cv2.resize(img, 
                               (img.shape[1] // scale_factor, img.shape[0] // scale_factor), 
                               interpolation=cv2.INTER_LINEAR)
        
        # Upscale image to original size (pixelation effect)
        pixelated_img = cv2.resize(small_img, 
                                   (img.shape[1], img.shape[0]), 
                                   interpolation=cv2.INTER_NEAREST)

        output_path = os.path.join(output_dir, filename)
        cv2.imwrite(output_path, pixelated_img)

# Example usage
input_dir = './flickrfaceshq-dataset-ffhq'  # Use raw string
output_dir = '/content/pxelated'      # Use raw string
create_pixelated_images(input_dir, output_dir)

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def extract_features(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    # Sharpness feature
    laplacian = cv2.Laplacian(img, cv2.CV_64F)
    sharpness = laplacian.var()
    
    # Blockiness feature
    h, w = img.shape
    blockiness = 0.0
    block_size = 8
    for i in range(block_size, h, block_size):
        blockiness += np.sum(np.abs(img[i, :] - img[i - 1, :]))
    for j in range(block_size, w, block_size):
        blockiness += np.sum(np.abs(img[:, j] - img[:, j - 1]))
    
    return [sharpness, blockiness]

# Paths to your image directories
pixelated_dir = './flickrfaceshq-dataset-ffhq'
non_pixelated_dir = '/content/pxelated'

# Prepare the dataset
X = []
y = []

for filename in os.listdir(pixelated_dir):
    if filename.endswith(('.jpg', '.png', '.jpeg')):
        features = extract_features(os.path.join(pixelated_dir, filename))
        X.append(features)
        y.append(1)  # Pixelated

for filename in os.listdir(non_pixelated_dir):
    if filename.endswith(('.jpg', '.png', '.jpeg')):
        features = extract_features(os.path.join(non_pixelated_dir, filename))
        X.append(features)
        y.append(0)  # Non-pixelated

X = np.array(X)
y = np.array(y)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
